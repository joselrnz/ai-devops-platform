# OpenTelemetry Collector configuration

mode: daemonset  # Run on every node

# Image
image:
  repository: otel/opentelemetry-collector-k8s
  tag: 0.91.0

# Resources
resources:
  limits:
    cpu: 500m
    memory: 1Gi
  requests:
    cpu: 200m
    memory: 512Mi

# Ports configuration
ports:
  # OTLP
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    hostPort: 4317
    protocol: TCP
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    hostPort: 4318
    protocol: TCP

  # Jaeger
  jaeger-compact:
    enabled: true
    containerPort: 6831
    servicePort: 6831
    hostPort: 6831
    protocol: UDP
  jaeger-grpc:
    enabled: true
    containerPort: 14250
    servicePort: 14250
    hostPort: 14250
    protocol: TCP
  jaeger-thrift:
    enabled: true
    containerPort: 14268
    servicePort: 14268
    hostPort: 14268
    protocol: TCP

  # Zipkin
  zipkin:
    enabled: true
    containerPort: 9411
    servicePort: 9411
    hostPort: 9411
    protocol: TCP

  # Prometheus
  prometheus:
    enabled: true
    containerPort: 8888
    servicePort: 8888
    protocol: TCP

# Configuration
config:
  receivers:
    # OTLP receiver
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318

    # Jaeger receiver
    jaeger:
      protocols:
        grpc:
          endpoint: 0.0.0.0:14250
        thrift_http:
          endpoint: 0.0.0.0:14268
        thrift_compact:
          endpoint: 0.0.0.0:6831
        thrift_binary:
          endpoint: 0.0.0.0:6832

    # Zipkin receiver
    zipkin:
      endpoint: 0.0.0.0:9411

    # Prometheus receiver (scrape own metrics)
    prometheus:
      config:
        scrape_configs:
          - job_name: 'otel-collector'
            scrape_interval: 30s
            static_configs:
              - targets: ['localhost:8888']

  processors:
    # Batch processor
    batch:
      timeout: 10s
      send_batch_size: 1024

    # Memory limiter
    memory_limiter:
      check_interval: 1s
      limit_mib: 512
      spike_limit_mib: 128

    # Resource detection
    resourcedetection:
      detectors: [env, system, docker, ec2, gcp, azure]
      timeout: 5s

    # K8s attributes
    k8sattributes:
      auth_type: "serviceAccount"
      passthrough: false
      extract:
        metadata:
          - k8s.namespace.name
          - k8s.deployment.name
          - k8s.statefulset.name
          - k8s.daemonset.name
          - k8s.cronjob.name
          - k8s.job.name
          - k8s.node.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.pod.start_time
        labels:
          - tag_name: app.label.component
            key: app.kubernetes.io/component
            from: pod
      pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.ip
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
        - sources:
          - from: connection

    # Transform processor
    transform:
      trace_statements:
        - context: span
          statements:
            - set(attributes["deployment.environment"], "production")

  exporters:
    # Debug exporter
    logging:
      loglevel: info

    # Prometheus exporter
    prometheus:
      endpoint: "0.0.0.0:8889"
      namespace: otel
      const_labels:
        cluster: production

    # OTLP exporters
    otlp/tempo:
      endpoint: tempo-distributor:4317
      tls:
        insecure: true

    otlp/metrics:
      endpoint: prometheus-server:9090
      tls:
        insecure: true

    # Loki exporter
    loki:
      endpoint: http://loki-gateway/loki/api/v1/push
      labels:
        resource:
          container.name: "container_name"
          k8s.namespace.name: "namespace"
          k8s.pod.name: "pod"

  service:
    pipelines:
      # Traces pipeline
      traces:
        receivers: [otlp, jaeger, zipkin]
        processors: [memory_limiter, batch, k8sattributes, resourcedetection, transform]
        exporters: [otlp/tempo, logging]

      # Metrics pipeline
      metrics:
        receivers: [otlp, prometheus]
        processors: [memory_limiter, batch, resourcedetection]
        exporters: [prometheus, logging]

      # Logs pipeline
      logs:
        receivers: [otlp]
        processors: [memory_limiter, batch, k8sattributes, resourcedetection]
        exporters: [loki, logging]

    telemetry:
      logs:
        level: info
      metrics:
        address: 0.0.0.0:8888

# Service account
serviceAccount:
  create: true
  annotations: {}

# Pod annotations
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8888"
  prometheus.io/path: "/metrics"

# Service Monitor
serviceMonitor:
  enabled: true
  metricsEndpoints:
    - port: metrics
      interval: 30s

# Tolerations to run on all nodes
tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
    operator: Exists
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
    operator: Exists
